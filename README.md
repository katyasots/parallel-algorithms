# parallel-algorithms
## Запуск параллельной программы на различном числе одновременно работающих процессов
1. ​Написана параллельная программа MPI, где каждый процесс определяет свой ранг MPI_Comm_rank, после чего действия в программе разделяются. Все процессы, кроме процесса с рангом 0, передают значение своего ранга нулевому процессу. Процесс с рангом 0 сначала печатает значение своего ранга, а далее последовательно принимает сообщения с рангами процессов и также печатает их значения. При этом важно отметить, что порядок приема сообщений заранее не определен и зависит от условий выполнения параллельной программы (более того, этот порядок может изменяться от запуска к запуску).
2. ​Запуск программы на 1,2 … N процессах несколько раз.
3. Проанализирован порядок вывода сообщений на экран. Попытка вывести правило, определяющее порядок вывода сообщений.
4. Построен график времени работы программы в зависимости от числа запущенных процессов. Проведен анализ графика.
5. Построен график ускорения/замедления работы программы. Проведен анализ графика.
6. ​Программа изменена таким образом, чтобы порядок вывода сообщений на экран соответствовал номеру соответствующего процесса.
7. Сделана сеть Петри для двух вариантов MPI программы.
##  Использование функций обмена данными "Точка-точка" в библиотеке MPI
Написана программа, которая распараллеливает задачу нахождения нулей в массиве между процессами: каждый процесс ищет ноль локально, на своей части массива. Программа была реализована с помощью функций обмена данными “точка-точка” в библиотеке MPI: MPI_Send и MPI_Recv. 

## Использование аргументов-джокеров
Написана программа, имитирующая топологию “звезда”, где нулевой процесс реализует функцию центрального узла. В программе было задействовано использование специальных параметров: джокеров. 

Джокер – родовой термин, имеющий значение "что-либо, отвечающее очень общему множеству характеристик". MPI_ANY_SOURCE позволяет получателю получить сообщения от любого отправителя, а MPI_ANY_TAG позволяет получателю получить любой тип сообщения от отправителя. 
## Коллективные операции
Написана программа, использующая функцию MPI_Gather для пересылки сообщений в главный процесс и выводящая их в порядке возрастания рангов переславших их процессов. Перед этим была изучена функция MPI_Gather, которая как раз и служит для передачи данных от всех процессов одному.
## Группы процессов и коммуникаторы
Написана программа, использующая функцию MPI_Comm_split, которая производит расщепление процессов на четные и нечетные и позволяет дальше работать только с четными. Также в написанной программе была использована функция MPI_Reduce, которая позволяет собрать данные с нескольких процессов, произвести над ними какую-то операцию (в нашем случае это нахождение минимума) и отправить результат на определенный процесс (нулевой по условию).
## Виртуальные топологии
Написана программа, использующая функцию MPI_Cart_create, которая создает новый коммуникатор с декартовой топологией на основе существующего коммуникатора. Также в написанной программе была использована функция MPI_Cart_shift. Она позволяет определить, какой процесс является источником и какой процесс является назначением для пересылки данных в заданном направлении и с заданным шагом.
## Умножение матриц
Изучен параллельный алгоритм умножения матриц, а также написана соответствующая программа для реализации как последовательного, так и параллельного подходов. Реализация этих алгоритмов позволила не только освоить основы работы с MPI, но и ознакомиться с принципами блочного разбиения матриц.

Алгоритм Фокса продемонстрировал свою высокую эффективность при тестировании, особенно при работе с большими матрицами. Он эффективно распараллеливает процесс умножения, что позволяет значительно ускорить вычисления. Однако для малых матриц можно наблюдать снижение производительности, связанное с накладными расходами на коммуникацию между процессами. 

При оптимизации работы программы важно учитывать размер матриц и количество используемых процессоров. Для каждого размера матрицы существует оптимальное число процессоров, превышение которого не всегда ведет к пропорциональному ускорению. Кроме того, для достижения максимальной производительности необходимо обеспечить равномерное распределение нагрузки между процессами, что позволяет избежать простаивания и достичь максимальной эффективности работы программы.

### В каждой работе был построен график зависимости времени от количества процессов и входных данных. Также был построен график ускорения/замедления. Каждый из графиков был проанализирован.